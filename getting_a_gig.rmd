---
title: "Getting a Gig"
author: "Sean Corcoran, Sarah Dodamead, Christopher Matos, Ethan Tenison"
date: "3/9/2020"
output:
  word_document: default
  html_document: default
---

```{r libraries, message=FALSE, warning=FALSE}
list.of.packages <-
        c(
                "googledrive",
                "janitor",
                "dplyr",
                "caret"
                
                
           )
#new.packages <-list.of.packages[!(list.of.packages %in% installed.packages()[, "Package"])]
library(googledrive)
library(janitor)
library(dplyr)
library(caret)
library(stargazer)
```

## Pulling in the data 

```{r data, cache = TRUE}
 drive_download(as_id("1S4B1Txs-ycsyO0X6DEA5C1STHt1fXeOK"), overwrite = TRUE)
 data <- read.csv("EER396_Data_Set.csv", stringsAsFactors = FALSE)
 drive_download(as_id("11K-AoNWVL7WcPpRAUkdCEwIC-umiUtwx"), overwrite = TRUE)
 Submarkets <- read.csv("Submarkets.csv", stringsAsFactors = FALSE)
 data <- clean_names(data)
 #str(data)
 
 data <- cbind(data,Submarkets)
 data$DENSITY <- as.numeric(as.character(data$DENSITY))
 data$LOCALECODE <- as.numeric(as.character(data$LOCALECODE))
 data$x2020POP <- as.numeric(as.character(data$x2020POP))
 data$AREA <- as.numeric(as.character(data$AREA))
 



```


```{r summary statistics}
library(formattable)
applicantflow <- colSums(!is.na(data[,c(1, 40, 42:43, 46:51)]))/nrow(data)*100
applicantflow

applicantflow <- matrix(applicantflow, ncol=1, byrow=TRUE)
applicantflow <- as.data.frame(applicantflow, stringsAsFactors=FALSE)
applicantflow$Stage <- 1:10
applicantflow$V1 <- round(applicantflow$V1, digits = 1)


library(ggplot2)

bar <- ggplot(data=applicantflow,aes(x= Stage, y= V1)) +
  geom_bar(stat="identity")+geom_text(aes(label=V1), vjust=1.6, color="white", size=3.5)+
  theme_minimal()+ scale_y_continuous(labels = scales::percent_format(accuracy = 1))

bar

```


## Data Cleaning 

Everything before submitting profile has been removed. Even after profile submission, leads that have not provided their age have also been removed.

#### Variables that have been removed: 
-da_activated, this variable is no longer being used  
-background_submit_Date
-submit_profile_time, data before this point is insufficient 
-orientation_selection_time
-orientation_start_time (we need to check to see if this is valueable)
-waitlist_end_date  (this would be more helpful if we knew what date they were put on a waitlist)
-mvr_initiated  
-mvr_cleared 
-criminal_initiated
-criminal_cleared
-dropship_kit_ordered
-orient_date
-start_date  this is connected to activation which we also deleted 
-first_dash_date, this is removed after the converted variable is created 
-planned_time 
-apply_date (this value is important if we need to calculate new day variables)
-applied_submarket
-planned_sp
-planned_sm 
-offer_end
-is_waitlist, all the waitlisted leads were removed before removing the variable.
-current_wl_status 
-dash_day, was removed because we use first_dash_day
-NA's were removed from submit_profile_time because we don't have enough data on individuals who haven't made it past that step.
-da_bgc_info_sub, removed because everything NA
-x, just an indentifier that I think believe has any meaning
-dash_applicant_id, just an indentifier that I think believe has any meaning
-dasher_id, just an indentifier that I think believe has any meaning
-zipcode, it has non US zip codes, so I just took it out. 

#### Variables that have been created: 
-converted, binary variable describing if a lead has converted or not


### Variables that have been imputed: 
-phone model, blanks set to unknown
-phone os, blanks set to unknown
-phone_ornot, blanks set to unknown
-w9_signed, set to no 
-orientation_type, set to none if blank 
-offer, blanks set to none 
-offer_amt, NA's set to zero
-offer_deliv_req, NA's set to zero
-delivs, NA's set to zero


```{r datacleaning}
#All the variables with dates need to be converted to a character before they are converted to the date time format.
data$submit_profile_time <- as.character(data$submit_profile_time)
data$apply_date <- as.character(data$apply_date)
data$orientation_selection_time <- as.character(data$orientation_selection_time)
data$orientation_start_time <- as.character(data$orientation_start_time)
data$mvr_initiated <- as.character(data$mvr_initiated)
data$criminal_initiated <- as.character(data$criminal_initiated)
data$dropship_kit_ordered <- as.character(data$dropship_kit_ordered)
data$orient_date <- as.character(data$orient_date)
data$first_dash_date <- as.character(data$first_dash_date)
data$planned_time <- as.character(data$planned_time)


#Leads that converted are given a 1 in the converted column 
df <- data %>% mutate(converted = ifelse(!is.na(data$first_dash_date) & data$da_first_dash <=45, 1, 0)) %>% 
        filter(!is.na(submit_profile_time)) %>% 
        filter(is_waitlist != "waitlist") %>% 
        filter(!is.na(age)) %>% 
        filter(!is.na(DENSITY))  %>%
        mutate(submit_profile_time = as.Date(submit_profile_time, "%Y-%m-%d %H:%M:%S"), 
        apply_date = as.Date(apply_date, "%Y-%m-%d"),
         orientation_selection_time = as.Date(orientation_selection_time, "%Y-%m-%d %H:%M:%S"),
orientation_start_time  = as.Date(orientation_start_time , "%Y-%m-%d %H:%M:%S"),
 mvr_initiated = as.Date(mvr_initiated, "%Y-%m-%d %H:%M:%S"),
 criminal_initiated = as.Date(criminal_initiated, "%Y-%m-%d %H:%M:%S"),
 dropship_kit_ordered = as.Date(dropship_kit_ordered, "%Y-%m-%d %H:%M:%S"),
 orient_date = as.Date(orient_date, "%Y-%m-%d"),
 planned_time = as.Date(planned_time, "%Y-%m-%d"),
 first_dash_date = as.Date(first_dash_date, "%Y-%m-%d")) 

#Adding variables for days of the week that steps are completed 
df$submit_profile_wkd <- weekdays(df$submit_profile_time)
df$ apply_date_wkd <- weekdays(df$ apply_date)
df$orientation_selection_wkd <- weekdays(df$orientation_selection_time)
df$orientation_start_wkd <- weekdays(df$orientation_start_time)
df$mvr_initiated_wkd <- weekdays(df$mvr_initiated)
df$criminal_initiated_wkd <- weekdays(df$criminal_initiated)
df$dropship_kit_ordered_wkd <- weekdays(df$dropship_kit_ordered)
df$orient_date_wkd <- weekdays(df$orient_date)
df$planned_firstdash_wkd <- weekdays(df$planned_time)
df$first_dash_wkd <- weekdays(df$first_dash_date)


df <- df %>%
        select(-c("da_activated", "background_submit_date", "submit_profile_time", "orientation_selection_time","orientation_start_time", "mvr_initiated","mvr_cleared","criminal_initiated","criminal_cleared", "orient_date", "start_date", "planned_time", "waitlist_end_date" ,"dropship_kit_ordered","apply_date","planned_sp", "planned_sm", "offer_end", "is_waitlist", "current_wl_status","dash_day","da_bgc_info_sub", "x", "dasher_applicant_id", "dasher_id", "zip_code" ))

# Filling in blank data 
df$phone_model <- as.character(df$phone_model)
df$phone_os <- as.character(df$phone_os)
df$app_version <- as.character(df$app_version)
df$w9_signed <- as.character(df$w9_signed)
df$orientation_type <- as.character(df$orientation_type)
df$offer <- as.character(df$offer)

df$phone_model[df$phone_model == ''] <- "unknown"
df$phone_os[df$phone_os == ''] <- "unknown"
df$app_version <- ifelse(df$app_version == "", "0", "1") #here 1 is set to equal that they used a phone
df <- df %>% rename(phone_ornot = app_version)
df$phone_ornot <- as.factor(df$phone_ornot)
df$offer[df$offer == ''] <- "blank"
df$w9_signed[df$w9_signed == ''] <- "no"
df$orientation_type[df$orientation_type == ''] <- "none"
df$offer_amt[is.na(df$offer_amt)] <- 0
df$offer_deliv_req[is.na(df$offer_deliv_req)] <- 0
df$delivs[is.na(df$delivs)] <- 0
 
df$data_pulled <- '2020/01/24'
df$data_pulled <- as.Date(df$data_pulled,'%Y/%m/%d')
## df$first_dash_date <- as.Date(df$first_dash_date,'%Y/%m/%d')

df$days_employed <- round(difftime(df$data_pulled ,df$first_dash_date , units = c("days")))
df$days_employed <- as.numeric((df$days_employed))
df$Gig_Rate <- df$delivs/df$days_employed 
df <- subset(df, select = -c(data_pulled, first_dash_date))

#After changing variables to characters in order to fill in missing information, I changed all the character variables back to factor which is important when running the models 
df[sapply(df, is.character)] <- lapply(df[sapply(df, is.character)], as.factor)

 str(df) 


```


## Logistic Regression

```{r logistic_regression}
# da_mvr_bgc_start + da_mvr_bgc_pass +
logit <- glm(converted ~ age + orientation_type + channel + da_profile_submit + da_orientation_select
             + da_dropshipping_created + da_oriented + phone_ornot + DENSITY + LOCALE 
             + x2020POP + vehicle , data = df, family = "binomial")
summary(logit)


```
```{r}
#Logistic Regression Summary 

stargazer(logit, title = "Regression Results",  type = 'html', out= "logit.html", no.space = TRUE)

```


```{r linear regression with Gig Rate}
HireValuedf <- df[!is.na(df$Gig_Rate), ]
linreg <- lm(Gig_Rate ~ age + da_profile_submit + da_orientation_select
             + da_dropshipping_created + da_oriented + phone_ornot + DENSITY + LOCALE 
             + x2020POP , data = HireValuedf)
summary(linreg)


```
```{r}
#Logistic Regression Summary 

stargazer(linreg, title = "Linear Regression Gig-Rate Results",  type = 'html', out= "linreg.html", no.space = TRUE)

```


```{r linear regression with relevant variables at each step in application process}

dfstep <- df
dfstep$appsubmitted <- ifelse(!is.na(df$da_profile_submit), 1, 0)
dfstep$mvrstart <- ifelse(!is.na(df$da_mvr_bgc_start), 1, 0)
dfstep$mvrpassed <- ifelse(!is.na(df$da_mvr_bgc_pass), 1, 0)
dfstep$criminalstart <- ifelse(!is.na(df$da_crim_bgc_start), 1, 0)
dfstep$criminalpassed <- ifelse(!is.na(df$da_crim_bgc_pass), 1, 0)
dfstep$orientated <- ifelse(!is.na(df$da_oriented), 1, 0)
dfstep$plannedfirstdash <- ifelse(!is.na(df$da_pfd), 1, 0)
dfstep$converted <- ifelse(!is.na(df$da_first_dash), 1, 0)

##Gate 1: Application Submit
AppSubmitLogit <- glm(appsubmitted ~ age + DENSITY + LOCALE 
             + x2020POP + vehicle , data = dfstep, family = "binomial")
summary(AppSubmitLogit)

dfstep$appsubmitted <- replace(dfstep$appsubmitted, dfstep$appsubmitted == 0, NA)
dfstep2 <- dfstep[!is.na(dfstep$appsubmitted), ]

##Gate 2: MVR Check

MVRCheckLogit <- glm(mvrstart ~ age + DENSITY + LOCALE 
             + x2020POP + vehicle , data = dfstep2, family = "binomial")
summary(MVRCheckLogit)

dfstep2$mvrpassed <- replace(dfstep2$mvrpassed, dfstep2$mvrpassed == 0, NA)
dfstep3 <- dfstep2[!is.na(dfstep2$mvrpassed), ]

##Gate 3: Criminal BG Check

criminalBGLogit <- glm(criminalstart ~ age + DENSITY + LOCALE 
             + x2020POP + vehicle , data = dfstep3, family = "binomial")
summary(criminalBGLogit)

dfstep3$criminalpassed <- replace(dfstep3$criminalpassed, dfstep3$criminalpassed == 0, NA)
dfstep4 <- dfstep3[!is.na(dfstep3$criminalpassed), ]

##Gate 4: Completed Orientation

orientationLogit <- glm(orientated ~ age + DENSITY + LOCALE 
             + x2020POP + vehicle , data = dfstep4, family = "binomial")
summary(orientationLogit)

dfstep4$orientated <- replace(dfstep4$orientated, dfstep4$orientated == 0, NA)
dfstep5 <- dfstep4[!is.na(dfstep4$orientated), ]

##Gate 5: Scheduled First Dash

pfdLogit <- glm(plannedfirstdash ~ age + DENSITY + LOCALE 
             + x2020POP + vehicle , data = dfstep5, family = "binomial")
summary(pfdLogit)

dfstep5$plannedfirstdash <- replace(dfstep5$plannedfirstdash, dfstep5$plannedfirstdash == 0, NA)
dfstep6 <- dfstep5[!is.na(dfstep5$plannedfirstdash), ]

##Gate 6: Converted

convertLogit <- glm(converted ~ age + DENSITY + LOCALE 
             + x2020POP + vehicle , data = dfstep6, family = "binomial")
summary(convertLogit)

```
```{r}
#Gate Logistic Regression Summary 

stargazer(AppSubmitLogit, MVRCheckLogit, criminalBGLogit, orientationLogit, pfdLogit, convertLogit, title = "Regression Gate Results",  type = 'latex', out= "stats.html", no.space = TRUE)
```
```{r non_action bias logistic regression}
logit_non_action <- glm(converted ~ age + phone_os + channel + vehicle + offer + offer_amt + offer_deliv_req + LOCALE + x2020POP + AREA + DENSITY, data = df, family = "binomial")
summary(logit_non_action)
```
```{r logistic_regression_da action bias}

logit11<- glm(converted ~ da_profile_submit, data=df, family="binomial")
logit12<- glm(converted ~ da_mvr_bgc_start, data=df, family="binomial")
logit13<- glm(converted ~ da_mvr_bgc_pass, data=df, family="binomial")
logit14<- glm(converted ~ da_orientation_select, data=df, family="binomial")
logit15<- glm(converted ~ da_dropshipping_created, data=df, family="binomial")
logit16<- glm(converted ~ da_crim_bgc_start, data=df, family="binomial")
logit17<- glm(converted ~ da_crim_bgc_pass, data=df, family="binomial")
logit18<- glm(converted ~ da_oriented, data=df, family="binomial")
logit19<- glm(converted ~ da_pfd, data=df, family="binomial")

summary(logit11)
summary(logit12)
summary(logit13)
summary(logit14)
summary(logit15)
summary(logit16)
summary(logit17)
summary(logit18)
summary(logit19)


```


```{r da in last step in the funnel and control}
logit20<- glm(converted ~ da_pfd+age + phone_os + channel + vehicle + offer + offer_amt + offer_deliv_req + LOCALE + x2020POP + AREA + DENSITY, data=df, family="binomial")
summary(logit20)
```




```{r tree_total}

tree <- df %>% dplyr::select(age, phone_ornot, phone_model, phone_os, orientation_type, channel, vehicle, offer, offer_amt, LOCALE, x2020POP, DENSITY, converted) #I had to take submarket out because the tree tmethod has a 32 level limit 

### Split data into traiing/test index ###
set.seed(27)
train <- sample(c(TRUE,FALSE), nrow(tree), rep=TRUE, prob = c(0.6,0.4))
test <- (!train)
df_train <- tree[train,]

### Growing a decision tree ###

library(tree)

mod.tree <- tree(converted ~., data = df_train, mindev = 0.001, minsize = 10)  

summary(mod.tree)

plot(mod.tree)
text(mod.tree, pretty = 1)


### Prune tree with CV ###

#Find the best size of the tree - the point where deviance(dev) is lowest
mod.tree.cv <- cv.tree(mod.tree, FUN = prune.tree)
mod.tree.cv

plot(mod.tree.cv$size, mod.tree.cv$dev, type = "b")
#Seems like best size of the tree is 3 - lets use this to prune the tree

mod.tree.prune <- prune.tree(mod.tree, best = 3)

summary(mod.tree.prune)


par(xpd = TRUE)
plot(mod.tree.prune, type = "uniform")
title(main= "Full Funnel Model")
text(mod.tree.prune, pretty = 1, splits = TRUE, cex=.8)

### Predict Conversion, using the pruned tree ###
tree$convert.Pred <- predict(mod.tree.prune, newdata = tree)

#Reapply 50% classification threshold for predicted conversion
tree$convert.Pred.Class <- ifelse(tree$convert.Pred > 0.5, "Convert", "Did Not Convert")
table(tree$convert.Pred.Class)

tree$converted <- as.character(tree$converted)
tree <- tree %>% mutate(converted = ifelse(converted == "1", "Convert", "Did Not Convert"))



#For training set
print("Train set")
t <- table(TrueConvert = tree$converted[train], PredConvert = tree$convert.Pred.Class[train]) #How many instances were misclassified? Error rates?
t
#Accuracy Rate
(t[1,1] +t[2,2])/(t[1,1] +t[1,2] + t[2,1] +t[2,2])

#For test set
print("Test set")
t <- table(TrueConvert = tree$converted[test], PredConvert = tree$convert.Pred.Class[test]) #How many instances were misclassified? Error rates?
t
#Accuracy Rate
(t[1,1] +t[2,2])/(t[1,1] +t[1,2] + t[2,1] +t[2,2])

print((t[1,1])/ (t[2,1] +t[1,1]))
print((t[2,2])/ (t[2,2] +t[1,2]))


```


```{r tree_MVR_start}


tree <- dfstep2 %>% dplyr::select(age, mvrstart, da_profile_submit, phone_ornot, phone_model, phone_os, orientation_type, channel, vehicle, offer, offer_amt, LOCALE, x2020POP, DENSITY, submit_profile_wkd) 
### Split data into traiing/test index ###
set.seed(27)
train <- sample(c(TRUE,FALSE), nrow(tree), rep=TRUE, prob = c(0.6,0.4))
test <- (!train)
df_train <- tree[train,]

### Growing a decision tree ###

library(tree)

mod.tree <- tree(mvrstart ~., data = df_train, mindev = 0.001, minsize = 10)  

summary(mod.tree)

plot(mod.tree)
text(mod.tree, pretty = 1)


### Prune tree with CV ###

#Find the best size of the tree - the point where deviance(dev) is lowest
mod.tree.cv <- cv.tree(mod.tree, FUN = prune.tree)
mod.tree.cv

plot(mod.tree.cv$size, mod.tree.cv$dev, type = "b")
#Seems like best size of the tree is 5 - lets use this to prune the tree

mod.tree.prune <- prune.tree(mod.tree, best = 5)

summary(mod.tree.prune)


par(xpd = TRUE)
plot(mod.tree.prune)
title(main= "Gate #2 Motor Vehicle Registration")
text(mod.tree.prune, pretty = 1,  splits = TRUE, cex=.8)

### Predict Conversion, using the pruned tree ###
tree$convert.Pred <- predict(mod.tree.prune, newdata = tree)

#Reapply 50% classification threshold for predicted conversion
tree$convert.Pred.Class <- ifelse(tree$convert.Pred > 0.5, "1", "0")
table(tree$convert.Pred.Class)

tree$mvrstart <- as.character(tree$mvrstart)

#For training set
print("Train set")
t <-table(TrueConvert = tree$mvrstart[train], PredConvert = tree$convert.Pred.Class[train]) #How many instances were misclassified? Error rates?
t
#Accuracy Rate 
print((t[1,1] +t[2,2])/(t[1,1] +t[1,2] + t[2,1] +t[2,2]))


#For test set
print("Test set")
t <- table(TrueConvert = tree$mvrstart[test], PredConvert = tree$convert.Pred.Class[test]) #How many instances were misclassified? Error rates?
t 
#Accuracy Rate 
print((t[1,1] +t[2,2])/(t[1,1] +t[1,2] + t[2,1] +t[2,2]))


print((t[1,1])/ (t[2,1] +t[1,1]))
print((t[2,2])/ (t[2,2] +t[1,2]))


```

```{r tree_background}


##Gate 3: Criminal BG Check

tree <- dfstep3 %>% dplyr::select(age, criminalstart, da_mvr_bgc_start, phone_ornot, phone_model, phone_os, orientation_type, channel, vehicle, offer, offer_amt, LOCALE, x2020POP, DENSITY, mvr_initiated_wkd) 
### Split data into traiing/test index ###
set.seed(27)
train <- sample(c(TRUE,FALSE), nrow(tree), rep=TRUE, prob = c(0.6,0.4))
test <- (!train)
df_train <- tree[train,]

### Growing a decision tree ###

library(tree)

mod.tree <- tree(criminalstart ~., data = df_train, mindev = 0.001, minsize = 10)  

summary(mod.tree)

plot(mod.tree)
text(mod.tree, pretty = 1)


### Prune tree with CV ###

#Find the best size of the tree - the point where deviance(dev) is lowest
mod.tree.cv <- cv.tree(mod.tree, FUN = prune.tree)
mod.tree.cv

plot(mod.tree.cv$size, mod.tree.cv$dev, type = "b")
#Seems like best size of the tree is 4 - lets use this to prune the tree

mod.tree.prune <- prune.tree(mod.tree, best = 4)

summary(mod.tree.prune)


par(xpd = TRUE)
plot(mod.tree.prune)
title(main= "Gate #3 Background Check")
text(mod.tree.prune, pretty = 1,  splits = TRUE, cex=.8)




### Predict Conversion, using the pruned tree ###
tree$convert.Pred <- predict(mod.tree.prune, newdata = tree)

#Reapply 50% classification threshold for predicted conversion
tree$convert.Pred.Class <- ifelse(tree$convert.Pred > 0.5, "1", "0")
table(tree$convert.Pred.Class)

tree$mvrstart <- as.character(tree$criminalstart)

#For training set
print("Train set")
t <-table(TrueConvert = tree$criminalstart[train], PredConvert = tree$convert.Pred.Class[train]) #How many instances were misclassified? Error rates?
t
#Accuracy Rate 
print((t[1,1] +t[2,2])/(t[1,1] +t[1,2] + t[2,1] +t[2,2]))


#For test set
print("Test set")
t <- table(TrueConvert = tree$mvrstart[test], PredConvert = tree$convert.Pred.Class[test]) #How many instances were misclassified? Error rates?
t 
#Accuracy Rate 
print((t[1,1] +t[2,2])/(t[1,1] +t[1,2] + t[2,1] +t[2,2]))


print((t[1,1])/ (t[2,1] +t[1,1]))
print((t[2,2])/ (t[2,2] +t[1,2]))
```


```{r tree_completeorientation}

##Gate 4: Completed Orietation

tree <- dfstep4 %>% dplyr::select(age, orientated, da_crim_bgc_start, phone_ornot, phone_model, phone_os, orientation_type, channel, vehicle, offer, offer_amt, LOCALE, x2020POP, DENSITY, criminal_initiated_wkd) 

tree$orientated[is.na(tree$orientated)] = 0


### Split data into traiing/test index ###
set.seed(27)
train <- sample(c(TRUE,FALSE), nrow(tree), rep=TRUE, prob = c(0.6,0.4))
test <- (!train)
df_train <- tree[train,]

### Growing a decision tree ###

library(tree)

mod.tree <- tree(orientated ~., data = df_train, mindev = 0.001, minsize = 5)  

summary(mod.tree)

plot(mod.tree)
text(mod.tree, pretty = 1)


### Prune tree with CV ###

#Find the best size of the tree - the point where deviance(dev) is lowest
mod.tree.cv <- cv.tree(mod.tree, FUN = prune.tree)
mod.tree.cv

plot(mod.tree.cv$size, mod.tree.cv$dev, type = "b")
#Seems like best size of the tree is 2 - lets use this to prune the tree

mod.tree.prune <- prune.tree(mod.tree, best = 2)

summary(mod.tree.prune)

par(xpd = TRUE)
plot(mod.tree.prune)
title(main= "Gate #4 Completed Orientation")
text(mod.tree.prune, pretty = 1,  splits = TRUE, cex=.8)

### Predict Conversion, using the pruned tree ###
tree$convert.Pred <- predict(mod.tree.prune, newdata = tree)

#Reapply 50% classification threshold for predicted conversion
tree$convert.Pred.Class <- ifelse(tree$convert.Pred > 0.5, "1", "0")
table(tree$convert.Pred.Class)

tree$mvrstart <- as.character(tree$orientated)

#For training set
print("Train set")
t <-table(TrueConvert = tree$orientated[train], PredConvert = tree$convert.Pred.Class[train]) #How many instances were misclassified? Error rates?
t
#Accuracy Rate 
print((t[1,1] +t[2,2])/(t[1,1] +t[1,2] + t[2,1] +t[2,2]))


#For test set
print("Test set")
t <- table(TrueConvert = tree$mvrstart[test], PredConvert = tree$convert.Pred.Class[test]) #How many instances were misclassified? Error rates?
t 
#Accuracy Rate 
print((t[1,1] +t[2,2])/(t[1,1] +t[1,2] + t[2,1] +t[2,2]))

print((t[1,1])/ (t[2,1] +t[1,1]))
print((t[2,2])/ (t[2,2] +t[1,2]))

```


```{r schedule_first_dash}


##Gate 5: Planned first dash  

tree <- dfstep5 %>% dplyr::select(age, plannedfirstdash, da_oriented, phone_ornot, phone_model, phone_os, orientation_type, channel, vehicle, offer, offer_amt, LOCALE, x2020POP, DENSITY, orient_date_wkd) 


tree$plannedfirstdash[is.na(tree$plannedfirstdash)] = 0


### Split data into traiing/test index ###
set.seed(27)
train <- sample(c(TRUE,FALSE), nrow(tree), rep=TRUE, prob = c(0.6,0.4))
test <- (!train)
df_train <- tree[train,]

### Growing a decision tree ###

library(tree)

mod.tree <- tree(plannedfirstdash ~., data = df_train, mindev = 0.001, minsize = 5)  

summary(mod.tree)

plot(mod.tree)
text(mod.tree, pretty = 1)


### Prune tree with CV ###

#Find the best size of the tree - the point where deviance(dev) is lowest
mod.tree.cv <- cv.tree(mod.tree, FUN = prune.tree)
mod.tree.cv

plot(mod.tree.cv$size, mod.tree.cv$dev, type = "b")
#Seems like best size of the tree is 4 - lets use this to prune the tree

mod.tree.prune <- prune.tree(mod.tree, best = 4)

summary(mod.tree.prune)


par(xpd = TRUE)
plot(mod.tree.prune)
title(main= "Gate #5 Schedule First Dash")
text(mod.tree.prune, pretty = 1,  splits = TRUE, cex=.8)


### Predict Conversion, using the pruned tree ###
tree$convert.Pred <- predict(mod.tree.prune, newdata = tree)

#Reapply 50% classification threshold for predicted conversion
tree$convert.Pred.Class <- ifelse(tree$convert.Pred > 0.5, "1", "0")
table(tree$convert.Pred.Class)

tree$mvrstart <- as.character(tree$plannedfirstdash)

#For training set
print("Train set")
t <-table(TrueConvert = tree$plannedfirstdash[train], PredConvert = tree$convert.Pred.Class[train]) #How many instances were misclassified? Error rates?
t
#Accuracy Rate 
print((t[1,1] +t[2,2])/(t[1,1] +t[1,2] + t[2,1] +t[2,2]))


#For test set
print("Test set")
t <- table(TrueConvert = tree$plannedfirstdash[test], PredConvert = tree$convert.Pred.Class[test]) #How many instances were misclassified? Error rates?
t 
#Accuracy Rate 
print((t[1,1] +t[2,2])/(t[1,1] +t[1,2] + t[2,1] +t[2,2]))


print((t[1,1])/ (t[2,1] +t[1,1]))
print((t[2,2])/ (t[2,2] +t[1,2]))
```



```{r converted}
# Step 6 Conversion 

tree <- dfstep6 %>% dplyr::select(age, converted, da_pfd, phone_ornot, phone_model, phone_os, orientation_type, channel, vehicle, offer, offer_amt, LOCALE, x2020POP, DENSITY, planned_firstdash_wkd) 




### Split data into traiing/test index ###
set.seed(27)
train <- sample(c(TRUE,FALSE), nrow(tree), rep=TRUE, prob = c(0.6,0.4))
test <- (!train)
df_train <- tree[train,]

### Growing a decision tree ###

library(tree)

mod.tree <- tree(converted ~., data = df_train, mindev = 0.001, minsize = 5)  

summary(mod.tree)

plot(mod.tree)
text(mod.tree, pretty = 1)


### Prune tree with CV ###

#Find the best size of the tree - the point where deviance(dev) is lowest
mod.tree.cv <- cv.tree(mod.tree, FUN = prune.tree)
mod.tree.cv

plot(mod.tree.cv$size, mod.tree.cv$dev, type = "b")
#Seems like best size of the tree is 4 - lets use this to prune the tree

mod.tree.prune <- prune.tree(mod.tree, best = 2)

summary(mod.tree.prune)

par(xpd = TRUE)
plot(mod.tree.prune)
title(main= "Gate #6 Converted")
text(mod.tree.prune, pretty = 1,  splits = TRUE, cex=.8)


# There is not enough variation. Based on the 50% threshold I was using all the leads would convert. 
### Predict Conversion, using the pruned tree ###
tree$convert.Pred <- predict(mod.tree.prune, newdata = tree)

#Reapply 50% classification threshold for predicted conversion
tree$convert.Pred.Class <- ifelse(tree$convert.Pred > 0.5, "1", "0")
table(tree$convert.Pred.Class)

tree$converted <- as.character(tree$converted)

#For training set
print("Train set")
t <-table(TrueConvert = tree$converted[train], PredConvert = tree$convert.Pred.Class[train]) #How many instances were misclassified? Error rates?
t
#Accuracy Rate 
print((t[1,1] +t[2,2])/(t[1,1] +t[1,2] + t[2,1] +t[2,2]))


#For test set
print("Test set")
t <- table(TrueConvert = tree$converted[test], PredConvert = tree$convert.Pred.Class[test]) #How many instances were misclassified? Error rates?
t 
#Accuracy Rate 
print((t[1,1] +t[2,2])/(t[1,1] +t[1,2] + t[2,1] +t[2,2]))


print((t[1,1])/ (t[2,1] +t[1,1]))
print((t[2,2])/ (t[2,2] +t[1,2]))



```


```{r random_forest}


library(randomForest)
tree <- df %>% dplyr::select(age, phone_ornot, phone_model, phone_os, orientation_type, channel, vehicle, offer, offer_amt, LOCALE, x2020POP, DENSITY, converted) #I had to take submarket out because the tree tmethod has a 32 level limit 

tree$converted <- as.factor(tree$converted)

set.seed(27)
train <- sample(nrow(tree), 0.7*nrow(tree), replace = FALSE)
TrainSet <- tree[train,]
ValidSet <- tree[-train,]
summary(TrainSet)
summary(ValidSet)



# Create a Random Forest model with default parameters
model1 <- randomForest(converted ~ ., data = TrainSet, ntree = 200, mtry = 6, do.trace = TRUE, importance = TRUE)
model1

#Accuracy Rate was also close to 73%. Therefore, there was no improvement. 

```



```{r histogram_of_converted}
converted <- filter(df, converted == 1)
converted <- filter(converted, age <= 85)
p <- ggplot(converted) +
    geom_histogram(aes(x = age, y = ..density..),
   
                                   binwidth = 1, fill = "blue", color = "black")
p

```


```{r histogram_stacked_age}
theme_set(theme_bw())
both <- filter(df, age <= 85)
both$converted <- as.factor(both$converted)
b <- ggplot(data = both) +
    geom_histogram(aes(x = age, y = ..density.., fill = converted),color = "white", binwidth = 1) +
    theme(
         legend.key = element_rect(fill = "transparent"), 
         legend.spacing = unit(-1, "lines"),
         panel.background = element_blank(),
         axis.line = element_line(colour = "black"),
         text=element_text(face = "bold", size=12),
         axis.title.y = element_text(vjust = 2),
         plot.title = element_text(hjust = 0.5)) +
    xlab("Age") +
    ylab("Percentage of Applicants") +
    labs(fill = "Converted", title = "Percentage of Total Applicants by Conversion factor")
b

```

```{r hist_vehicle}

theme_set(theme_bw())
both <- df
both$converted <- as.factor(both$converted)
b <- ggplot(data = both, aes(x=vehicle, fill = converted)) +
    geom_bar(color = "white") +
    theme(
         legend.key = element_rect(fill = "transparent"), 
         legend.spacing = unit(-1, "lines"),
         panel.background = element_blank(),
         axis.line = element_line(colour = "black"),
         text=element_text(face = "bold", size=12),
         axis.title.y = element_text(vjust = 2),
         plot.title = element_text(hjust = 0.5)) +
    xlab("Vehicle Type") +
    ylab("Total Applicants") +
    labs(fill = "Converted", title = "Total Applicants by Vehicle and Conversion factor")
b

```



```{r kernel_density}

kernel <- df %>% group_by(age) %>% summarize(pct_convert = mean(converted)) %>% filter(age <= 85)


k <- ggplot(kernel, aes(x=age, y=pct_convert)) +
    geom_line(color = "#CC4678FF", size = 1,stat="identity") +
    theme(
           legend.key = element_rect(fill = "transparent"), 
           legend.spacing = unit(-1, "lines"),
           panel.background = element_blank(),
           axis.line = element_line(colour = "black"),
           text=element_text(face = "bold", size=12),
           axis.title.y = element_text(vjust = 2),
           plot.title = element_text(hjust = 0.5)) +
      xlab("Age") +
      ylab("Percent Conversion") +
      labs(title = "Percentage of applicants who convert by age")

k

```

```{r drives}

drives <- df %>% filter(converted == 1) %>% group_by(age) %>% summarize(avg_drives = mean(delivs)) %>% filter(age <= 85) 


d <- ggplot(drives, aes(x=age, y=avg_drives)) +
      geom_line(color = "#0D0887FF", size = 1,stat="identity") +
      theme(
             legend.key = element_rect(fill = "transparent"), 
             legend.spacing = unit(-1, "lines"),
             panel.background = element_blank(),
             axis.line = element_line(colour = "black"),
             text=element_text(face = "bold", size=12),
             axis.title.y = element_text(vjust = 2),
             plot.title = element_text(hjust = 0.5)) +
        xlab("Age") +
        ylab("Number of Deliveries") +
        labs(title = "Average Deliveries by Age")

d


```


```{r drives_vehcile}

drives_vehicle <- df %>% filter(converted == 1) %>% group_by(vehicle) %>% summarize(avg_drives = mean(delivs))

theme_set(theme_bw())

b <- ggplot(data = drives_vehicle, aes(x=vehicle, y = avg_drives, fill = vehicle)) +
    geom_bar(color = "white", stat = "identity") +
    theme(
         legend.key = element_rect(fill = "transparent"), 
         legend.spacing = unit(-1, "lines"),
         panel.background = element_blank(),
         axis.line = element_line(colour = "black"),
         text=element_text(face = "bold", size=12),
         axis.title.y = element_text(vjust = 2),
         plot.title = element_text(hjust = 0.5)) +
    xlab("Vehicle Type") +
    ylab("Average Deliveries") +
    labs(fill = "Converted", title = "Average Deliveries by Vehicle")
b


```


```{r age_vehicle_average}

add_count_var <- mutate(df, n =1)

add_count_var <- filter(add_count_var, age <= 85)

age_avg_vehicle_per <- tbl_df(add_count_var)

age_avg_vehicle_per <- age_avg_vehicle_per %>% group_by(age, vehicle) %>% summarise (n = n()) %>% mutate(freq = n / sum(n))

# Visualization
ggplot(age_avg_vehicle_per, aes(x = age, y = freq)) + 
  geom_line(aes(color = vehicle),  size = 1) +
    theme(
         legend.key = element_rect(fill = "transparent"), 
         legend.spacing = unit(-1, "lines"),
         panel.background = element_blank(),
         axis.line = element_line(colour = "black"),
         text=element_text(face = "bold", size=12),
         axis.title.y = element_text(vjust = 2),
         plot.title = element_text(hjust = 0.5)) +
    xlab("Age") +
    ylab("Proportion of Vehicle") +
    labs(fill = "Vehicle", title = "Proportion of Vehicles by Age")


```

```{r 5 k fold cross validation on step 6 in the funnel}
# Directly doing k-fold cross validation
library(boot)
k <- 5
cv.error <- rep(0,k)
for (i in 1:k){
 glm.fit <- glm(converted ~ age + channel + phone_ornot + DENSITY + LOCALE 
             + x2020POP + vehicle + da_pfd, data = dfstep6, family = "binomial")
 cv.error[i] <- cv.glm(dfstep6, glm.fit, K=k)$delta[1]
}
cv.error
```


```{r confusion matrix from step 6}
dfstep6$set <- sample(c("Train", "Test"), nrow(dfstep6), prob = c(0.8,0.2), replace = TRUE)
df.train <- dfstep6[dfstep6$set=="Train",]
df.test <- dfstep6[dfstep6$set=="Test",]

#threshold = .5
mod.log <- glm(converted ~ age + channel + phone_ornot + DENSITY + LOCALE 
             + x2020POP + vehicle + da_pfd, data = df.train, family = "binomial") 
pred.log <- predict(mod.log, df.test, type = "response") 
pred.log.class <- if_else(pred.log >= 0.5, 1,0) 
mce.log <- mean(df.test$converted != pred.log.class) 
mce.log
 
#confusionMatrix(mod.log, df.test$converted)
table(df.test$converted, pred.log.class)
#accuracy = (5+28922)/(5+28922+10+4075) = .8763

##threshold .7
mod.log <- glm(converted ~ age + channel + phone_ornot + DENSITY + LOCALE 
             + x2020POP + vehicle + da_pfd, data = df.train, family = "binomial") 
pred.log <- predict(mod.log, df.test, type = "response") 
pred.log.class <- if_else(pred.log >= 0.7, 1,0) 
mce.log <- mean(df.test$converted != pred.log.class) 
mce.log
 

table(df.test$converted, pred.log.class)
#accuracy = (140+28635)/(140+28635+297+3940) = .87165

##threshold .4
mod.log <- glm(converted ~ age + channel + phone_ornot + DENSITY + LOCALE 
             + x2020POP + vehicle + da_pfd, data = df.train, family = "binomial") 
pred.log <- predict(mod.log, df.test, type = "response") 
pred.log.class <- if_else(pred.log >= 0.4, 1,0) 
mce.log <- mean(df.test$converted != pred.log.class) 
mce.log
 

table(df.test$converted, pred.log.class)
#accuracy = (2+28932)/(2+28932+4078) = .87647
```

```{r confusion matrix for contril variables}
df$set <- sample(c("Train", "Test"), nrow(df), prob = c(0.8,0.2), replace = TRUE)
df.train <- df[df$set=="Train",]
df.test <- df[df$set=="Test",]

#threshold = .5
mod.log <- glm(converted ~ age + channel + phone_ornot + DENSITY + LOCALE 
             + x2020POP + vehicle, data = df.train, family = "binomial") 
pred.log <- predict(mod.log, df.test, type = "response") 
pred.log.class <- if_else(pred.log >= 0.5, 1,0) 
mce.log <- mean(df.test$converted != pred.log.class) 
mce.log
 
#confusionMatrix(mod.log, df.test$converted)
table(df.test$converted, pred.log.class)
#accuracy = (63961+10467)/(63961+10467+18870+8101) = .7340

##threshold .6
mod.log <- glm(converted ~ age + channel + phone_ornot + DENSITY + LOCALE 
             + x2020POP + vehicle, data = df.train, family = "binomial") 
pred.log <- predict(mod.log, df.test, type = "response") 
pred.log.class <- if_else(pred.log >= 0.6, 1,0) 
mce.log <- mean(df.test$converted != pred.log.class) 
mce.log
 

table(df.test$converted, pred.log.class)
#accuracy = (69890+3161)/(26176+2172+69890+3161) = .7204

##threshold .4
mod.log <- glm(converted ~ age + channel + phone_ornot + DENSITY + LOCALE 
             + x2020POP + vehicle, data = df.train, family = "binomial") 
pred.log <- predict(mod.log, df.test, type = "response") 
pred.log.class <- if_else(pred.log >= 0.4, 1,0) 
mce.log <- mean(df.test$converted != pred.log.class) 
mce.log
 

table(df.test$converted, pred.log.class)
#accuracy = (46458+25120)/(46458+25120+4217+25604) = .7095

```

```{r day start in funnel}
library(tidyverse)
theme_set(theme_bw())
dfnona <- df %>% drop_na(planned_firstdash_wkd)
both <- dfnona
both$converted <- as.factor(both$converted)
b <- ggplot(data = both, aes(x=planned_firstdash_wkd, fill = converted)) +
    geom_bar(color = "white") +
    theme(
         legend.key = element_rect(fill = "transparent"), 
         legend.spacing = unit(-1, "lines"),
         panel.background = element_blank(),
         axis.line = element_line(colour = "black"),
         text=element_text(face = "bold", size=12),
         axis.title.y = element_text(vjust = 2),
         plot.title = element_text(hjust = 0.5)) +
    xlab("Day of Week") +
    ylab("Total Applicants") +
    labs(fill = "Converted", title = "Total Applicants by Day of Week in Last Step and Conversion factor")
b


```

```{r conversion_density_by day of week}

kernel <- df %>% drop_na(planned_firstdash_wkd) %>% group_by(planned_firstdash_wkd) %>% summarize(pct_convert = mean(converted)) 


k <- ggplot(kernel, aes(x=planned_firstdash_wkd, y=pct_convert)) +
    geom_point(color = "#CC4678FF", size = 1,stat="identity") +
    theme(
           legend.key = element_rect(fill = "transparent"), 
           legend.spacing = unit(-1, "lines"),
           panel.background = element_blank(),
           axis.line = element_line(colour = "black"),
           text=element_text(face = "bold", size=12),
           axis.title.y = element_text(vjust = 2),
           plot.title = element_text(hjust = 0.5)) +
      xlab("day of week the planned time occured") +
      ylab("Percent Conversion") +
      labs(title = "Percentage of applicants who convert by day of week they planned")

k

```


